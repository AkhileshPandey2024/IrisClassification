{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8e16af-b643-4d3e-acf6-b50801b94d0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standards imports\n",
    "import os\n",
    "#Third-Party imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import datasets\n",
    "\n",
    "#Local imports\n",
    "sns.set()\n",
    "data=datasets.load_iris()\n",
    "df=pd.DataFrame(data[\"data\"],columns=data[\"feature_names\"])\n",
    "df[\"target\"]=data[\"target\"]\n",
    "df.head()\n",
    "df.describe()\n",
    "col=\"sepal length (cm)\"\n",
    "df[col].hist()\n",
    "plt.suptitle(col)\n",
    "plt.show()\n",
    "\n",
    "col=\"sepal width (cm)\"\n",
    "df[col].hist()\n",
    "plt.suptitle(col)\n",
    "plt.show()\n",
    "\n",
    "col=\"petal length (cm)\"\n",
    "df[col].hist()\n",
    "plt.suptitle(col)\n",
    "plt.show()\n",
    "\n",
    "col=\"petal width (cm)\"\n",
    "df[col].hist()\n",
    "plt.suptitle(col)\n",
    "plt.show()\n",
    "\n",
    "# create new column with the species name;\n",
    "df[\"target_name\"]=df[\"target\"].map({0:\"setosa\",1:\"versicolor\",2:\"virginica\"})\n",
    "\n",
    "col=\"sepal length (cm)\"\n",
    "sns.relplot(x=col, y=\"target\", hue=\"target_name\",data=df)\n",
    "_=plt.suptitle(col,y=1.02)\n",
    "\n",
    "\n",
    "col=\"sepal width (cm)\"\n",
    "sns.relplot(x=col, y=\"target\", hue=\"target_name\",data=df)\n",
    "_=plt.suptitle(col,y=1.02)\n",
    "\n",
    "col=\"petal length (cm)\"\n",
    "sns.relplot(x=col, y=\"target\", hue=\"target_name\",data=df)\n",
    "_=plt.suptitle(col,y=1.02)\n",
    "\n",
    "\n",
    "col=\"petal width (cm)\"\n",
    "sns.relplot(x=col, y=\"target\", hue=\"target_name\",data=df)\n",
    "_=plt.suptitle(col,y=1.02)\n",
    "\n",
    "sns.pairplot(df,hue=\"target_name\")\n",
    "from sklearn.model_selection import train_test_split\n",
    "df_train,df_test=train_test_split(df,test_size=0.25)\n",
    "df_train.shape\n",
    "print(df_train)\n",
    "df_train.head()\n",
    "\n",
    "x_train=df_train.drop(columns=[\"target\",\"target_name\"]).values\n",
    "y_train=df_train[\"target\"].values\n",
    "x_train\n",
    "y_train\n",
    "\n",
    "\n",
    "\n",
    "def single_feature_prediction(petal_length):\n",
    "    \"\"\"Predicts the Iris species given the petal length\"\"\"\n",
    "    if petal_length<2.5:\n",
    "        return 0  # 0- setosa\n",
    "    elif petal_length<4.8:\n",
    "        return 1 #1- versicolor\n",
    "    else:\n",
    "        return 2 #2-virginica\n",
    "x_train[:,2]\n",
    "\n",
    "manual_y_predictions=np.array([single_feature_prediction(val) for val in x_train[:,2]])\n",
    "manual_model_accuracy=np.mean(manual_y_predictions==y_train)\n",
    "print(f\"Manual model accuracy:{manual_model_accuracy*100: .2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model=LogisticRegression(max_iter=200)\n",
    "# xt stands x_train, and xv stands for x_validation\n",
    "xt,xv,yt,yv=train_test_split(x_train,y_train,test_size=0.25)\n",
    "model.fit(xt,yt)\n",
    "y_pred=model.predict(xv)  #y_predict\n",
    "model.score(xv,yv)\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score,cross_val_predict\n",
    "model=LogisticRegression(max_iter=200)\n",
    "model.fit(xt,yt)\n",
    "accuracies=cross_val_score(model,x_train,y_train,cv=5,scoring=\"accuracy\")\n",
    "np.mean(accuracies)\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "print(\"\\nDecision Tree Classifier:\")\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_accuracies = cross_val_score(dt_model, x_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(f\"Decision Tree Accuracy: {np.mean(dt_accuracies) * 100:.2f}%\")\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "print(\"\\nK-Nearest Neighbors Classifier:\")\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)  # You can tweak n_neighbors\n",
    "knn_accuracies = cross_val_score(knn_model, x_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(f\"KNN Accuracy (k=3): {np.mean(knn_accuracies) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "print(\"\\nSupport Vector Machine Classifier:\")\n",
    "svm_model = SVC(kernel='linear')  # You can also try 'rbf', 'poly', etc.\n",
    "svm_accuracies = cross_val_score(svm_model, x_train, y_train, cv=5, scoring=\"accuracy\")\n",
    "print(f\"SVM Accuracy (Linear Kernel): {np.mean(svm_accuracies) * 100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "y_pred=cross_val_predict(model,x_train,y_train,cv=5)\n",
    "predicted_correctly_mask=y_pred==y_train\n",
    "not_predicted_correctly=~predicted_correctly_mask\n",
    "x_train[not_predicted_correctly]\n",
    "\n",
    "df_predictions=df_train.copy()\n",
    "df_predictions[\"correct_prediction\"]=predicted_correctly_mask\n",
    "df_predictions[\"prediction\"]=y_pred\n",
    "df_predictions[\"prediction_label\"]=df_predictions[\"prediction\"].map({0:\"setosa\",1:\"versicolor\",2:\"virginica\"})\n",
    "df_predictions.head()\n",
    "\n",
    "\n",
    "sns.scatterplot(x=\"petal length (cm)\",y=\"petal width (cm)\", hue=\"prediction_label\",data=df_predictions)\n",
    "sns.scatterplot(x=\"petal length (cm)\",y=\"petal width (cm)\", hue=\"target_name\",data=df_predictions)\n",
    "\n",
    "\n",
    "def plot_incorrect_predictions(df_predictions,x_axis_feature,y_axis_feature):\n",
    "    fig, axs=plt.subplots(2,2,figsize=(10,10))\n",
    "    axs=axs.flatten()\n",
    "    sns.scatterplot(x=x_axis_feature,y=y_axis_feature,hue=\"prediction_label\",data=df_predictions,ax=axs[0])\n",
    "    sns.scatterplot(x=x_axis_feature,y=y_axis_feature,hue=\"target_name\",data=df_predictions,ax=axs[1])\n",
    "\n",
    "    sns.scatterplot(x=x_axis_feature,y=y_axis_feature,hue=\"correct_prediction\",data=df_predictions,ax=axs[2])\n",
    "    axs[3].set_visible(False)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_incorrect_predictions(df_predictions,\"petal length (cm)\", \"petal width (cm)\")\n",
    "\n",
    "\n",
    "\n",
    "for reg_param in (0.1,0.3,0.9,1,1.3,1.8,2,5,10,15):\n",
    "    print(reg_param)\n",
    "    model=LogisticRegression(max_iter=200,C =reg_param)\n",
    "    accuracies=cross_val_score(model,x_train,y_train,cv=5,scoring=\"accuracy\")\n",
    "    print(f\"Accuracy :{np.mean(accuracies)*100:.2f}%\")\n",
    "\n",
    "\n",
    "\n",
    "model=LogisticRegression(max_iter=200,C=2)\n",
    "x_test=df_train.drop(columns=[\"target\",\"target_name\"]).values\n",
    "y_test=df_train[\"target\"].values\n",
    "\n",
    "model.fit(x_train,y_train)\n",
    "model.get_params()\n",
    "y_test_pred=model.predict(x_test)\n",
    "y_test_pred.shape\n",
    "\n",
    "test_set_correctly_classified=y_test_pred==y_test\n",
    "test_set_accuracy=np.mean(test_set_correctly_classified)\n",
    "print(f\"Test set accuracy :{test_set_accuracy*100:.2f}\")\n",
    "\n",
    "df_predictions_test.head()\n",
    "\n",
    "plot_incorrect_predictions(df_predictions,x_axis_feature=\"petal length (cm)\",y_axis_feature=\"petal width (cm)\")\n",
    "\n",
    "\n",
    "\n",
    "#Creating a confusion matrix for each model;\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Recreate the models for prediction on df_train (same as your x_test/y_test)\n",
    "# Logistic Regression\n",
    "model = LogisticRegression(max_iter=200, C=2)\n",
    "model.fit(xt, yt)\n",
    "y_pred_logreg = model.predict(xt)\n",
    "\n",
    "# Decision Tree\n",
    "dt_model = DecisionTreeClassifier()\n",
    "dt_model.fit(x_train, y_train)\n",
    "y_pred_dt = dt_model.predict(xt)\n",
    "\n",
    "# K-Nearest Neighbors\n",
    "knn_model = KNeighborsClassifier(n_neighbors=3)\n",
    "knn_model.fit(x_train, y_train)\n",
    "y_pred_knn = knn_model.predict(xt)\n",
    "\n",
    "# Support Vector Machine\n",
    "svm_model = SVC(kernel='linear')\n",
    "svm_model.fit(x_train, y_train)\n",
    "y_pred_svm = svm_model.predict(xt)\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(yt, y_pred_logreg), display_labels=[\"setosa\", \"versicolor\", \"virginica\"]).plot(ax=axes[0, 0], colorbar=False)\n",
    "axes[0, 0].set_title(\"Logistic Regression\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(yt, y_pred_dt), display_labels=[\"setosa\", \"versicolor\", \"virginica\"]).plot(ax=axes[0, 1], colorbar=False)\n",
    "axes[0, 1].set_title(\"Decision Tree\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(yt, y_pred_knn), display_labels=[\"setosa\", \"versicolor\", \"virginica\"]).plot(ax=axes[1, 0], colorbar=False)\n",
    "axes[1, 0].set_title(\"K-Nearest Neighbors\")\n",
    "\n",
    "ConfusionMatrixDisplay(confusion_matrix(yt, y_pred_svm), display_labels=[\"setosa\", \"versicolor\", \"virginica\"]).plot(ax=axes[1, 1], colorbar=False)\n",
    "axes[1, 1].set_title(\"Support Vector Machine\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abdd578-bb05-4150-964a-65f11962fdb9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
